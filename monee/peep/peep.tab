/* Peephole table. Some limitations on the rules:
 * There can be at most one jCC instruction in a peephole rule.
 * There can be at most one MEM access in a peephole rule.
 * Temporaries tr0 and tr1 must never be used as index registers in a memory
 *   access, because in that case, esp would not be subtituted for them.
 * Specify index register (use %eiz) for every memory access
 * Always use the 'd' suffix for "read-only" register variables in output code.
 * The variables (vr0..vr7, tr0..tr7, C0..C7) should always be used in ascending
 * order. i.e., start with '0' suffix and continue with '1', '2', ...
 */
#include "peepgen_offsets.h"
#include "peep/peeptab_defs.h"

#define entry entry_16
#include "peep.tab.16"
#undef entry

#include "peep.tab.excp"

entry:
  cli
  --
  movb $0, %gs:(vcpu + VCPU_IF_OFF)
  ==

entry:
  sti
  --
  movw $2, %gs:(vcpu + VCPU_IF_OFF)
  ==

entry:
  ret
  --
  %tr0d: eax
  %tr1d: no_eax
  --
  excp00: #restore_temporaries
  popl %tr1d
  excp00: #pushl %tr1d
  JUMP_INDIRECT_AFTER_TR1_RESTORE_USE_EAX_TEMP(%tr1d, tr0)
  ==

entry:
  jmp *%vr0d
  --
  %tr0d: eax
  %vr0d: no_eax
  --
  excp00: #restore_temporaries
  JUMP_INDIRECT_USE_EAX_TEMP(%vr0d, 0)
  ==

entry:
  jmp *%eax
  --
  %tr0d: eax
  %tr1d: no_eax
  --
  excp00: #restore_temporaries
  movl %eax, %tr1d
  JUMP_INDIRECT_AFTER_TR1_RESTORE_USE_EAX_TEMP(%tr1d, tr0)
  ==

entry:
  jmp *%vseg0:MEM32
  --
  %tr0d: eax
  %tr1d: no_eax
  %vseg0: no_cs_gs
  --
  excp00: #restore_temporaries
  movl %vseg0:MEM32, %tr1d
  JUMP_INDIRECT_AFTER_TR1_RESTORE_USE_EAX_TEMP(%tr1d, tr0)
  ==

entry:
  jmp *%vseg0:MEM32
  --
  %tr0d: eax
  %tr1d: no_eax
  %vseg0: cs_gs
  --
  excp00: #restore_temporaries
  MOV_SEG_TO_GS_USE_EAX_TEMP0_NO_EAX_TEMP1(vseg0,tr0, tr1)
  movl %gs:MEM32, %tr1d
  RESTORE_GS
  JUMP_INDIRECT_AFTER_TR1_RESTORE_USE_EAX_TEMP(%tr1d, tr0)
  ==

entry:
  mov %vr0d, %cr3
  --
  CALLOUT2(callout_mov_to_cr3, %vr0d, $fallthrough_addr)
  ==

entry:
  int $C0
  --
  CALLOUT2(callout_int, $C0, $fallthrough_addr)
  ==

entry:
  .byte 0xcd, 0x03                    #int 3
  --
  CALLOUT0(callout_int3)
  ==

entry:
  movl %cr0, %vr0d
  --
  movl %gs:(vcpu+VCPU_CR0_OFF), %vr0d
  ==

entry:
  mov %cr2, %vr0d
  --
  movl %gs:(vcpu+VCPU_CR2_OFF), %vr0d
  ==

entry:
  mov %cr3, %vr0d
  --
  movl %gs:(vcpu+VCPU_CR3_OFF), %vr0d
  ==

entry:
  mov %cr4, %vr0d
  --
  movl %gs:(vcpu+VCPU_CR4_OFF), %vr0d
  ==

entry:
  mov %vr0d, %cr4
  --
  movl %vr0d, %gs:(vcpu+VCPU_CR4_OFF)
  ==

entry:
  movl %vr0d, %cr0
  --
  CALLOUT1(callout_mov_to_cr0, %vr0d)
  ==

entry:
  lgdt %vseg0:MEM32
  --
  %tr0d: no_eax
  --
  leal MEM32, %tr0d
  CALLOUT2(callout_restore_tr0_and_lgdt, $tr0d, $vseg0)
  ==

entry:
  lidt %vseg0:MEM32
  --
  %tr0d: no_eax
  --
  leal MEM32, %tr0d
  CALLOUT2(callout_restore_tr0_and_lidt, $tr0d, $vseg0)
  ==

entry:
  ltr %vr0w
  --
  CALLOUT1(callout_ltr_val, %vr0d)
  ==

entry:
  ltr %vseg0:MEM32
  --
  %tr0d: no_eax
  --
  leal MEM32, %tr0d
  CALLOUT2(callout_restore_tr0_and_ltr_mem, $tr0d, $vseg0)
  ==


entry:
#<debug>
  ljmp $C0, $C1
  --
  CALLOUT2(callout_ljmp, $C0, $C1)
  ==

entry:
#<debug>
  ljmp *%vseg0:MEM32
  --
  leal MEM32, %tr0d
  CALLOUT3(callout_restore_tr0_and_ljmp_indir, $tr0d, $vseg0, $4)
  ==

entry:
  lcall $C0, $C1
  --
  CALLOUT4(callout_lcall, $C0, $C1, $4, $fallthrough_addr)
  ==

entry:
  lret
  --
  CALLOUT2(callout_lret, $4, $0)
  ==

entry:
  lret $C0
  --
  CALLOUT2(callout_lret, $4, $C0)
  ==

entry:
  jCC _(C0)
  --
  jCC target_C0
  jmp tc_next_eip
  EDGE0: set_eip($C0); EXIT_TB
  EDGE1: set_eip($fallthrough_addr); EXIT_TB
  ==

entry:
  jecxz _(C0)
  --
  jecxz 1f
  jmp tc_next_eip
  1: jmp target_C0
  EDGE0: set_eip($C0); EXIT_TB
  EDGE1: set_eip($fallthrough_addr); EXIT_TB
  ==

entry:
  jmp _(C0)
  --
  jmp target_C0
  EDGE0: set_eip($C0)
         EXIT_TB
  ==

entry:
  call _(C0)
  --
  pushl $fallthrough_addr
  jmp target_C0
  EDGE0: set_eip($C0)
         EXIT_TB
  ==

entry:
  call *%vr0d
  --
  %tr0d: eax
  %vr0d: no_eax
  --
  excp00: #restore_temporaries
  pushl $fallthrough_addr
  excp00: #addl $4, %esp
  JUMP_INDIRECT_USE_EAX_TEMP(%vr0d, 0)
  ==

entry:
  call *%eax
  --
  %tr0d: eax
  %tr1d: no_eax
  --
  excp00: #restore_temporaries
  pushl $fallthrough_addr
  excp00: #addl $4, %esp
  movl %eax, %tr1d
  JUMP_INDIRECT_AFTER_TR1_RESTORE_USE_EAX_TEMP(%tr1d, tr0)
  ==

#XXX: 2 rules: one for cs_gs, another for no_cs_gs
entry:
  call *%vseg0:MEM32
  --
  %tr0d: eax
  %tr1d: no_eax
  --
  excp00: #restore_temporaries
  movl %vseg0:MEM32, %tr1d
  pushl $fallthrough_addr
  excp00: #addl $4, %esp
  JUMP_INDIRECT_AFTER_TR1_RESTORE_USE_EAX_TEMP(%tr1d, tr0)
  ==

entry:
  loop _(C0)
  --
  %tr0d: eax
  --
  HANDLE_LOOP(ecx)
# no_restore_temporary
  ==

entry:
  loope _(C0)
  --
  %tr0d: eax
  --
  HANDLE_LOOPX(jnz, ecx)
# no_restore_temporary
  ==

entry:
  loopne _(C0)
  --
  %tr0d: eax
  --
  HANDLE_LOOPX(jz, ecx)
# no_restore_temporary
  ==

#define STRING_OP_SUFFIX(opc,suffix,len)                                    \
    entry:                                                                >>\
      opc##suffix                                                         >>\
      --                                                                  >>\
      CALLOUT2(callout_##opc, $len, $prefixNN)                            >>\
      ==>>

#define STRING_OP(opc)                                                      \
    STRING_OP_SUFFIX(opc, b, 1)                                           >>\
    STRING_OP_SUFFIX(opc, w, 2)                                           >>\
    STRING_OP_SUFFIX(opc, l, 4)

STRING_OP(ins)
STRING_OP(outs)



#define STRING_OP_REAL_SUFFIX(opc,suffix,len)                               \
    entry:                                                                >>\
      opc##suffix                                                         >>\
      --                                                                  >>\
      cpu: real no_excp                                                   >>\
      --                                                                  >>\
      CALLOUT2(callout_real_##opc, $len, $prefixNN)                       >>\
      ==>>

#define STRING_OP_REAL(opc)                                                 \
    STRING_OP_REAL_SUFFIX(opc, b, 1)                                      >>\
    STRING_OP_REAL_SUFFIX(opc, w, 2)                                      >>\
    STRING_OP_REAL_SUFFIX(opc, l, 4)

//STRING_OP_REAL(movs)
//STRING_OP_REAL(cmps)
//STRING_OP_REAL(stos)
//STRING_OP_REAL(lods)
//STRING_OP_REAL(scas)


#define IN_OP(opc,inputname,outputname,extended_inputname,len)              \
    entry:                                                                >>\
      opc inputname, outputname                                           >>\
      --                                                                  >>\
      CALLOUT2(callout_in, extended_inputname, $len)                      >>\
      ==>>

IN_OP(inb, $C0, %al, $C0, 1)
IN_OP(inw, $C0, %ax, $C0, 2)
IN_OP(inl, $C0, %eax, $C0, 4)

IN_OP(inb, %dx, %al, %edx, 1)
IN_OP(inw, %dx, %ax, %edx, 2)
IN_OP(inl, %dx, %eax, %edx, 4)

#define OUT_OP(opc,inputname,outputname,extended_outputname,len)            \
    entry:                                                                >>\
      opc inputname, outputname                                           >>\
      --                                                                  >>\
      CALLOUT2(callout_out, extended_outputname, $len)                    >>\
      ==>>

OUT_OP(outb, %al, $C0, $C0, 1)
OUT_OP(outw, %ax, $C0, $C0, 2)
OUT_OP(outl, %eax, $C0, $C0, 4)

OUT_OP(outb, %al, %dx, %edx, 1)
OUT_OP(outw, %ax, %dx, %edx, 2)
OUT_OP(outl, %eax, %dx, %edx, 4)

entry:
  popf
  --
  %tr0d: no_esp
  %tr1d: no_esp
  --
  popl %tr0d
  movl %tr0d, %tr1d
  andl $IF_MASK, %tr1d
  setne %gs:(vcpu + VCPU_IF_OFF)
  movl %tr0d, %tr1d
  andl $IOPL_MASK, %tr1d
  shrl $IOPL_SHIFT, %tr1d
  movw %tr1w, %gs:(vcpu + VCPU_IOPL_OFF)
  movl %tr0d, %tr1d
  andl $AC_MASK, %tr1d
  setne %gs:(vcpu + VCPU_AC_OFF)
  movl %tr0d, %tr1d
  orl  $(IOPL_MASK | IF_MASK), %tr1d
  andl $(~AC_MASK), %tr1d
  pushl %tr1d
  popfl
  movl %tr0d, %ss:-4(%esp,%eiz,1)
  ==

entry:
  pushf
  --
  %tr0d: eax
  %tr1d: no_eax_esp
  --
  lahf
  movl %tr0d, %gs:(vcpu + VCPU_SCRATCH_OFF(0))
  pushfl
  movl %ss:(%esp,%eiz,1), %tr1d
  andl $(~IF_MASK & ~IOPL_MASK), %tr1d
  #save IF
  movw %gs:(vcpu + VCPU_IF_OFF), %tr0w
  movzwl %tr0w, %tr0d
  shll $IF_SHIFT, %tr0d
  orl %tr0d, %tr1d
  #save IOPL
  movw %gs:(vcpu + VCPU_IOPL_OFF), %tr0w
  movzwl %tr0w, %tr0d
  shll $IOPL_SHIFT, %tr0d
  orl %tr0d, %tr1d
  #save AC
  movw %gs:(vcpu + VCPU_AC_OFF), %tr0w
  movzwl %tr0w, %tr0d
  shll $AC_SHIFT, %tr0d
  orl %tr0d, %tr1d
  movl %tr1d, %ss:(%esp,%eiz,1)
  movl %gs:(vcpu + VCPU_SCRATCH_OFF(0)), %tr0d
  sahf
  ==

entry:
  iret
  --
  CALLOUT0(callout_iret)
  ==

entry:
  hlt
  --
  CALLOUT0(callout_hlt)
  ==

entry:
  mov %vr0d, %vseg0
  --
  %tr0d: no_eax_esp
  %vseg0: no_cs_gs
  --
  MOV_REG_TO_SEG_USE_NO_EAX_TEMP(%vr0, %vseg0, $vseg0, tr0)
  ==

entry:
  mov %vr0d, %gs
  --
  %tr0d: no_eax_esp
  %tr1d: no_eax_esp
  --
  excp00: #restore_temporaries
  mov %gs, %tr1d
  MOV_REG_TO_SEG_USE_NO_EAX_TEMP(%vr0, %gs, $R_GS, tr0)
  mov %tr1d, %gs
  movzwl %vr0w, %tr1d
  mov %tr1d, %gs:(vcpu + VCPU_SEGS_OFF(R_GS))
  ==

#XXX: need four cases for mov %vseg1:MEM32, %vseg0

entry:
  pop %vseg0
  --
  %tr0d: no_eax_esp
  %tr1d: no_eax_esp
  %vseg0: no_cs_gs
  --
  excp00: #restore_temporaries
  popl %tr1d
  excp00: #pushl %tr1d
  MOV_REG_TO_SEG_USE_NO_EAX_TEMP(%tr1, %vseg0, $vseg0, tr0)
  ==

entry:
  pop %gs
  --
  %tr0d: no_eax_esp
  %tr1d: no_eax_esp
  %tr2d: no_eax_esp
  --
  excp00: #restore_temporaries
  mov %gs, %tr2d
  popl %tr1d
  excp00: #pushl %tr1d
  MOV_REG_TO_SEG_USE_NO_EAX_TEMP(%tr1, %gs, $R_GS, tr0)
  mov %tr2d, %gs
  movzwl %tr1w, %tr2d
  mov %tr2d, %gs:(vcpu + VCPU_SEGS_OFF(R_GS))
  ==

entry:
  push %vseg0
  --
  %tr0d: no_esp
  --
  excp00: #restore_temporaries
  movl $vseg0, %tr0d
  leal (vcpu + VCPU_ORIG_SEGS_OFF(0))(,%tr0d,4), %tr0d
  pushl %gs:(%tr0d)
  ==

entry:
  invd
  --
  --
  CALLOUT0(callout_invd);
  ==
